# Marketing AI Assistant
A comprehensive AI-powered marketing campaign generator that helps businesses create data-driven marketing strategies through interactive conversations.  
Built with **Next.js** (frontend) and **FastAPI** (backend), powered by **Ollama** for local AI inference.

## ğŸš€ Features
### Core Capabilities
- Interactive Conversation Flow
- User Context Understanding
- Real-time Web Search
- Campaign Generation
- Early Exit Option

### Campaign Deliverables
- Strategy Overview
- Ad Copy
- Email Drafts
- Social Media Content
- Content Calendar
- Key Messaging

### Technical Features
- Real-time web integration
- PDF export
- Responsive UI
- Context-aware state management
- Robust error handling

## ğŸ› ï¸ Tech Stack
### Frontend
- Next.js 14
- TypeScript
- Tailwind CSS
- Axios
- Lucide React
- jsPDF

### Backend
- FastAPI
- Ollama
- Pydantic
- Serper API
- Uvicorn

## ğŸ“¦ Installation
### Prerequisites
- Python 3.8+
- Node.js 18+
- Ollama installed
- Serper API key (optional)

## Backend Setup
### 1. Clone & install
```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure environment
Create `backend/.env`

### 3. Start Ollama
```bash
ollama serve
ollama pull llama2
```

### 4. Run backend
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## Frontend Setup
```bash
cd frontend
npm install
npm run dev
```
Open: http://localhost:3000

## ğŸ¯ Usage
- Guided context collection
- Early generation via `"generate campaign now"`
- Optional web search
- Multi-variation content generation
- PDF export

## ğŸ”§ API Endpoints
- POST /chat
- POST /campaign/generate-now
- POST /search/enhance-context
- POST /conversation/{user_id}/reset
- GET /conversation/{user_id}/context
- GET /health
- GET /config
- GET /

## ğŸ—ï¸ Project Structure
```
marketing-ai-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ services.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â””â”€â”€ frontend/
    â”œâ”€â”€ app/
    â”œâ”€â”€ package.json
    â””â”€â”€ tailwind.config.js
```

## ğŸ” How It Works
- Context collection â†’ Insight gathering â†’ Campaign generation
- Uses Ollama for local inference
- Context-aware system prompts
- Robust fallback & error handling

## âš™ï¸ Configuration
- Ollama model, temperature, tokens
- Serper API settings
- Conversation state management

## ğŸš¨ Error Handling
- Web search fallbacks
- JSON parsing recovery
- Session restoration
- Input validation

## ğŸ“Š Performance
- Caching
- Async operations
- Health checks
- Logs & analytics

## ğŸ”’ Security
- No data persistence
- Sanitized inputs
- CORS control
- API key security

## ğŸ§ª Testing
### Backend
```bash
pytest tests/
```
### Frontend
```bash
npm test
```

## ğŸš€ Deployment
### Backend
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```
### Frontend
```bash
npm run build
npm start
```

## ğŸ¤ Contributing
- Fork â†’ Branch â†’ Implement â†’ PR
- PEP8, TypeScript, ESLint, docs

## ğŸ“ License
MIT License

## ğŸ™ Acknowledgments
- Ollama
- FastAPI
- Next.js
- Serper API


Set the environment variable in your terminal before running your Python script:

On Linux/macOS:

bash
export FAL_KEY="your-api-key-here"
On Windows (Command Prompt):

cmd
set FAL_KEY=your-api-key-here
On Windows (PowerShell):

powershell
$env:FAL_KEY="your-api-key-here"